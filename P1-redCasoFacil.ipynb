{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "proyecto1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9fYVKd4NVmu",
        "colab_type": "text"
      },
      "source": [
        "#Se importan las librerias"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTmpoaPVNs9x",
        "colab_type": "code",
        "outputId": "3b25664e-0fdb-4625-ef81-e888b4b86d93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        }
      },
      "source": [
        "!pip install tensorflow==1.14.0"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow==1.14.0 in /usr/local/lib/python3.6/dist-packages (1.14.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.12.0)\n",
            "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.14.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (3.10.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.0.8)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.1.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.18.2)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.9.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.27.2)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.34.2)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.3.3)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.8.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.2.0)\n",
            "Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.14.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.12.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==1.14.0) (46.0.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==1.14.0) (2.10.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.2.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (1.0.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlUVSk_p-jK0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import zipfile\n",
        "import os \n",
        "import math\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt \n",
        "from sklearn import preprocessing, model_selection\n",
        "from keras.utils import to_categorical \n",
        "import keras\n",
        "from keras import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZOEm0GIAJt64",
        "colab_type": "text"
      },
      "source": [
        "#Se cargan los datos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "teybXDkyjTby",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mundo1 = zipfile.ZipFile(\"Mun1.zip\", mode=\"r\")\n",
        "mundo1.extractall(None)\n",
        "mundo8 = zipfile.ZipFile(\"Mun8.zip\", mode=\"r\") \n",
        "mundo8.extractall(None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DoOfqHBdLRxV",
        "colab_type": "text"
      },
      "source": [
        "#Se definen las variables 'X' y 'y'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OclGdAAnmVFB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "024d2a63-337c-4c00-e84c-5c1735dfe1db"
      },
      "source": [
        "imagenes = []\n",
        "nivel = []\n",
        "imagenes1 = mundo1.namelist()\n",
        "imagenes8 = mundo8.namelist()\n",
        "#Se agregan las imagenes del mundo 1\n",
        "i = 1\n",
        "while(i<len(imagenes1)):\n",
        "  filepath = os.path.join(\"\", imagenes1[i]) \n",
        "  image = plt.imread(filepath)\n",
        "  imagenes.append(image)\n",
        "  nivel.append(0)\n",
        "  i += 1\n",
        "#Se agreagan las imagenes del mundo 8\n",
        "i = 1\n",
        "while(i<len(imagenes8)):\n",
        "  filepath = os.path.join(\"\", imagenes8[i]) \n",
        "  image = plt.imread(filepath)\n",
        "  imagenes.append(image)\n",
        "  nivel.append(1)\n",
        "  i += 1\n",
        "#Se define la salida por categorias, para que se puedan distinguir las clases.\n",
        "y = to_categorical(np.array(nivel))\n",
        "X = np.array(imagenes, dtype=np.uint8)  \n",
        "print('Dimensiones de las variables: ', X.shape, y.shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dimensiones de las variables:  (16435, 200, 240, 3) (16435, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eno0dMvLJz7p",
        "colab_type": "text"
      },
      "source": [
        "#Preprocesamiento de datos\n",
        "\n",
        "\n",
        "1.   Se realiza el conjunto de entrenamiento al tomar el 10% de los datos totales.\n",
        "2.   Se realiza el conjunto de validación al tomar el 10% de los datos de entrenamiento.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "593x9HKD2feD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Se definen los porcentajes de entrenamiento y validación\n",
        "porcentajeEntrenamiento = 0.8\n",
        "porcentajeValidación = 0.9\n",
        "#Se determinan los datos de entrenamiento, prueba y validación\n",
        "x_entrenamiento, x_prueba, y_entrenamiento, y_prueba = model_selection.train_test_split(X,y,test_size=1-porcentajeEntrenamiento)\n",
        "x_entrenamiento, x_validacion, y_entrenamiento, y_validacion = model_selection.train_test_split(x_entrenamiento,y_entrenamiento,test_size=1-porcentajeValidación)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdEmJ-u-40ws",
        "colab_type": "text"
      },
      "source": [
        "#Se crea la red neuronal\n",
        "\n",
        "\n",
        "1.   La red neuronal se realizará a partir de keras\n",
        "2.   La red va a ser de tipo sequencial, para poder trabajar con diferentes capas, que se encarguen de diferentes funciones.\n",
        "3.   La primera capa es de tipo Conv2D, esto con el fin de especificar que se esta recibiendo una imagen de dimenciones (200,240,3). Tambien se especifica que su activación es de tipo relu, ya que siempre se recomienda hacer pooling justo despues de haber aplicado una capa con no-linealidad.\n",
        "4.   Lo siguiente es utilizar MaxPooling2D, para agrupar la presencia de aquellos patrones que se repiten con mayor frecuencia en cada segmento de la imagen.\n",
        "5.   A continuación se utiliza Dropout, para igualar a 0 un pequeño porcentaje de la información y con esto evitar overfitting en el entrenamiento.\n",
        "6.   Se utiliza flatten para acoplar los datos que salen de la capa dentreada y ajustarlos para que sirvan como entrada de la capa escondida de clasificación que se utiliza.\n",
        "7.   Se establece una capa central para para clasificación y se utiliza una activacion tipo relu, ya que sabemos suele entregar los mejores resultados en clasificación.\n",
        "8.   Nuevamente utilizamos Dropout para evitar overfitting.\n",
        "9.   Ya para terminar se crea una capa se salida con activación softmax para comprimir los nCentral datos obtenidos por la capa de clasificación, en tan solo nFinal datos que corresponderan al npumero de salidas.\n",
        "10.  Por ultimo se realiza la compilación de la red, la cual cuenta con:\n",
        "      1.  Entropia cruzada como función de error, dado que estamos haciendo un clasificador.\n",
        "      2.  Descenso de gradiente estocastico como algoritmo de optimización.\n",
        "      3.  La tasa de aprendisaje se fijo en 0.0005, luego de varias pruebas.\n",
        "      4.  Ademas tambien se indica que debe retornar el porcentaje de aciertos del entrenamiento.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5nlzoNNo5Axo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Función que crea la red neuronal con base en el número de neuronas de cada una de sus capas\n",
        "def crearRed(nInicial, nCentral, nSalida):\n",
        "  #Se crea la red sequencial\n",
        "  RedNeuronal = Sequential()\n",
        "  #Se crea la capa de entrada\n",
        "  RedNeuronal.add(Conv2D(nInicial, kernel_size=(3, 3),activation='relu',padding='same',input_shape=(200, 240, 3)))\n",
        "  #Se realiza una agrupación de datos\n",
        "  RedNeuronal.add(MaxPooling2D())\n",
        "  RedNeuronal.add(MaxPooling2D())\n",
        "  RedNeuronal.add(MaxPooling2D())\n",
        "  RedNeuronal.add(MaxPooling2D())\n",
        "  RedNeuronal.add(MaxPooling2D())\n",
        "  #Se ajusta los datos para conectarlos a la siguiente capa\n",
        "  RedNeuronal.add(Dropout(0.5))\n",
        "  RedNeuronal.add(Flatten())\n",
        "  #Se crea la capa central de clasificación\n",
        "  RedNeuronal.add(Dense(nCentral, activation='relu'))\n",
        "  RedNeuronal.add(Dense(nCentral, activation='relu')) \n",
        "  RedNeuronal.add(Dropout(0.5)) \n",
        "  #Se crea la capa de salida\n",
        "  RedNeuronal.add(Dense(nSalida, activation='softmax'))\n",
        "  #Se compila la red\n",
        "  tasa = 0.0005\n",
        "  RedNeuronal.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.SGD(lr=tasa,decay=tasa/100), metrics=['accuracy'])\n",
        "  #Se retorna la red creada\n",
        "  return RedNeuronal"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LxOVgkA-Ic1T",
        "colab_type": "text"
      },
      "source": [
        "#Validación de número de neuronas\n",
        "\n",
        "\n",
        "1.   Se van a realizar pruebas de 10 en 10 en cada una de las capas.\n",
        "2.   Dado que nuestra variable de salida esta restringida a dos posibles salidas debido a la funcion to_categorical(), la ultima capa tambien debera ser de dos salidas, para que la respuesta se pueda comparar con los datos reales.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2GZHlv9LHVY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "outputId": "ca0dff98-ce30-4f78-ef5e-9c7a4f4b255d"
      },
      "source": [
        "#Se crea el vector con el número de neuronas\n",
        "neuronas = [30, 40, 50]\n",
        "i = 0\n",
        "#Se recorre la capa de entrada\n",
        "while(i<len(neuronas)):\n",
        "  j=0\n",
        "  #Se recorre la capa central\n",
        "  while(j<len(neuronas)):\n",
        "    #Se crea y valida la red neuronal\n",
        "    RedNeuronal = crearRed(neuronas[i], neuronas[j], 2)\n",
        "    fit = RedNeuronal.fit(x_validacion, y_validacion, batch_size=64, epochs=10, verbose=0)\n",
        "    print('[',neuronas[i],',',neuronas[j],', 2 ]:','Tasa de acierto: ',(fit.history['acc']))\n",
        "    j += 1\n",
        "  i += 1"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 30 , 30 , 2 ]: Tasa de acierto:  [0.4714828905043946, 0.50114068456929, 0.5003802282501989, 0.5262357420341144, 0.537642586185905, 0.5346007612268281, 0.5110266160375718, 0.5520912547755151, 0.5292775673104783, 0.5239543727822177]\n",
            "[ 30 , 40 , 2 ]: Tasa de acierto:  [0.5079847915544256, 0.4996197719764347, 0.5057034220758952, 0.5277566540150588, 0.5391634987334335, 0.5718631183693165, 0.5186311791604916, 0.5361216730264656, 0.582509506202016, 0.5543726235968078]\n",
            "[ 30 , 50 , 2 ]: Tasa de acierto:  [0.5057034227331328, 0.501901140707074, 0.5193916350036519, 0.5285171109913873, 0.5026615975927491, 0.5140684413139358, 0.5239543726915642, 0.5155893537254841, 0.5384030418930852, 0.5338403049077372]\n",
            "[ 40 , 30 , 2 ]: Tasa de acierto:  [0.5049429664593685, 0.5361216736837032, 0.5346007609548677, 0.5117870730139004, 0.5110266160375718, 0.5178707225014502, 0.5239543733941285, 0.5285171103341498, 0.5361216736837032, 0.5627376430841453]\n",
            "[ 40 , 40 , 2 ]: Tasa de acierto:  [0.5072243353259881, 0.5087452477828631, 0.5216730038249447, 0.5178707232040144, 0.5072243347140772, 0.5323193923602086, 0.5475285178354937, 0.5437262365119993, 0.5703422057311345, 0.5893536127112211]\n",
            "[ 40 , 50 , 2 ]: Tasa de acierto:  [0.49885931631458125, 0.51711026679427, 0.5247148289200018, 0.5041825102309311, 0.5186311794777787, 0.5346007611361746, 0.5041825100949509, 0.5277566540603855, 0.5117870729685736, 0.5604562744894862]\n",
            "[ 50 , 30 , 2 ]: Tasa de acierto:  [0.4836501901820585, 0.49657794688137763, 0.503422053345256, 0.5011406850905473, 0.501901141273658, 0.5239543733941285, 0.49961977193110796, 0.5262357422154212, 0.5178707225014502, 0.485171102729587]\n",
            "[ 50 , 40 , 2 ]: Tasa de acierto:  [0.5057034227784596, 0.5041825102762577, 0.5087452478735166, 0.5072243353259881, 0.5117870729685736, 0.5148288973610664, 0.5186311794777787, 0.52851711047013, 0.5163498106111591, 0.5193916351849589]\n",
            "[ 50 , 50 , 2 ]: Tasa de acierto:  [0.5117870729232469, 0.5148288979729773, 0.4988593160879476, 0.5079847908971881, 0.5087452479188433, 0.5163498099539217, 0.5102661604663719, 0.5003802282501989, 0.5133079852894685, 0.5087452478735166]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mNqqU-HhaqYJ",
        "colab_type": "text"
      },
      "source": [
        "#Se selecciona la red neuronal a crear\n",
        "\n",
        "1.   Se va a tomar la red con las neuronas [50, 50, 2], dado que se obxervaron muy buenos resultados para este tipo de red.\n",
        "2.   Se entrena la red con los datos de en trenamiento y esto luego de 5 epochs.\n",
        "3.   Se guarda la red obtenida.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "elwgtekpbUHH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "401d4bc0-d094-43fb-addb-e41ae313183e"
      },
      "source": [
        "#Se crea la red neuronal\n",
        "RedNeuronal = crearRed(50, 50, 2)\n",
        "#Se muestra como esta compuesta la red\n",
        "RedNeuronal.summary()\n",
        "#Se entrena la red\n",
        "fit = RedNeuronal.fit(x_entrenamiento, y_entrenamiento, batch_size=64, epochs=15, verbose=1)\n",
        "#Se guarda la red creada\n",
        "RedNeuronal.save(\"CasoSencillo.h5py\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_2 (Conv2D)            (None, 200, 240, 50)      1400      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 100, 120, 50)      0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 50, 60, 50)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2 (None, 25, 30, 50)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2 (None, 12, 15, 50)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_10 (MaxPooling (None, 6, 7, 50)          0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 6, 7, 50)          0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 2100)              0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 50)                105050    \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 50)                2550      \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 2)                 102       \n",
            "=================================================================\n",
            "Total params: 109,102\n",
            "Trainable params: 109,102\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "11833/11833 [==============================] - 417s 35ms/step - loss: 7.7229 - acc: 0.5054\n",
            "Epoch 2/50\n",
            "11833/11833 [==============================] - 423s 36ms/step - loss: 6.7571 - acc: 0.5647\n",
            "Epoch 3/50\n",
            "11833/11833 [==============================] - 423s 36ms/step - loss: 4.7150 - acc: 0.6866\n",
            "Epoch 4/50\n",
            "11833/11833 [==============================] - 420s 35ms/step - loss: 3.7231 - acc: 0.7400\n",
            "Epoch 5/50\n",
            "11833/11833 [==============================] - 417s 35ms/step - loss: 2.3897 - acc: 0.7872\n",
            "Epoch 6/50\n",
            "11833/11833 [==============================] - 415s 35ms/step - loss: 0.8241 - acc: 0.8109\n",
            "Epoch 7/50\n",
            "11833/11833 [==============================] - 417s 35ms/step - loss: 0.4185 - acc: 0.8297\n",
            "Epoch 8/50\n",
            "11833/11833 [==============================] - 416s 35ms/step - loss: 0.3377 - acc: 0.8551\n",
            "Epoch 9/50\n",
            "11833/11833 [==============================] - 415s 35ms/step - loss: 0.3061 - acc: 0.8716\n",
            "Epoch 10/50\n",
            "11833/11833 [==============================] - 415s 35ms/step - loss: 0.2703 - acc: 0.8852\n",
            "Epoch 11/50\n",
            "11833/11833 [==============================] - 415s 35ms/step - loss: 0.2558 - acc: 0.8959\n",
            "Epoch 12/50\n",
            "11833/11833 [==============================] - 414s 35ms/step - loss: 0.2448 - acc: 0.9003\n",
            "Epoch 13/50\n",
            "11833/11833 [==============================] - 415s 35ms/step - loss: 0.2208 - acc: 0.9048\n",
            "Epoch 14/50\n",
            "11833/11833 [==============================] - 413s 35ms/step - loss: 0.2124 - acc: 0.9113\n",
            "Epoch 15/50\n",
            "11833/11833 [==============================] - 411s 35ms/step - loss: 0.1987 - acc: 0.9189\n",
            "Epoch 16/50\n",
            "  704/11833 [>.............................] - ETA: 6:30 - loss: 0.2185 - acc: 0.9105"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-3e98df428833>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mRedNeuronal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#Se entrena la red\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mfit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRedNeuronal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_entrenamiento\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_entrenamiento\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;31m#Se guarda la red creada\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mRedNeuronal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"CasoSencillo.h5py\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1176\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m     def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    202\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2977\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2979\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2980\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2981\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2935\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2936\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2937\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2938\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Zd2LGHuZC-e",
        "colab_type": "text"
      },
      "source": [
        "#Evaluación de la red neuronal\n",
        "Una vez evaluado el error empirico y rteniendo en cuenta el número de datos \\\\\n",
        "Se observa que el indice de confianza es :\n",
        "##$(1-\\delta) = (1 - 2/\\exp(|S{\\small text}|{ \\cdot 2\\varepsilon^2 }))$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NAUJW3NZUs_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "7271e794-70bb-41c9-d37f-48d85f6355c9"
      },
      "source": [
        "#Se prueba la red neuronal\n",
        "prueba = RedNeuronal.evaluate(x_prueba, y_prueba, verbose=0)\n",
        "#Se calcula el erro empirico, numero de datos y indice de confianza\n",
        "E_empirico = 1 - prueba[1]\n",
        "N_datos = y_prueba.shape[0]\n",
        "confianza = 1 - 2/math.exp(N_datos*2*(E_empirico**2))\n",
        "RedNeuronal.save(\"/content/drive/My Drive/Archivos MachineLearning/CasoSencillo.h5py\")\n",
        "print('Número de datos de prueba = ' + str(N_datos))\n",
        "print('Error empirico = ' + str(E_empirico))\n",
        "print('indice de confianza = ' + str(confianza))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Número de datos de prueba = 3287\n",
            "Error empirico = 0.031335564271853134\n",
            "indice de confianza = 0.9968551184248527\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-97P0H550Qr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "outputId": "8ae94709-e979-4985-d5b9-73efc01edb15"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ev5NDvwSlh-_",
        "colab_type": "text"
      },
      "source": [
        "#Referencias\n",
        "\n",
        "\n",
        "*   [1]   \"Home - Keras Documentation\", Keras.io, 2020. [Online]. Available: https://keras.io/. [Accessed: 20- Mar- 2020].\n",
        "*   [2]   \"Clasificación de Imágenes en Python\", Aprende Machine Learning, 2020. [Online]. Available: https://www.aprendemachinelearning.com/clasificacion-de-imagenes-en-python/. [Accessed: 20- Mar- 2020].\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}